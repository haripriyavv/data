# -*- coding: utf-8 -*-
"""Project 2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1X7_1qsco0bkJKlSgYu7Mj-fMQGBp9Gzp
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

sns.set(style='whitegrid')

df = pd.read_csv("/content/solarpowergeneration.csv")

print("Shape of dataset:", df.shape)
print("\nData Types:\n", df.dtypes)
print("\nFirst 5 rows:\n", df.head())

print("\nMissing Values:\n", df.isnull().sum())

print("\nSummary Statistics:\n", df.describe().T)

df.hist(figsize=(16, 12), bins=30, edgecolor='black')
plt.suptitle("Feature Distributions", fontsize=16)
plt.tight_layout()
plt.show()

plt.figure(figsize=(10, 8))
sns.heatmap(df.corr(), annot=True, cmap="coolwarm", fmt=".2f")
plt.title("Correlation Matrix")
plt.show()

features = df.columns.drop("power-generated")

plt.figure(figsize=(16, 20))
for i, col in enumerate(features, 1):
    plt.subplot(5, 2, i)
    sns.scatterplot(data=df, x=col, y="power-generated")
    plt.title(f"{col} vs Power Generated")
plt.tight_layout()
plt.show()

plt.figure(figsize=(16, 20))
for i, col in enumerate(df.columns, 1):
    plt.subplot(5, 2, i)
    sns.boxplot(data=df, y=col, color='orange')
    plt.title(f"Boxplot of {col}")
plt.tight_layout()
plt.show()

print("\nSkewness:\n", df.skew())
print("\nKurtosis:\n", df.kurt())

sample_df = df.sample(500, random_state=42) if len(df) > 500 else df

sns.pairplot(sample_df)
plt.suptitle("Pairplot of Sample Data", y=1.02)
plt.show()

plt.figure(figsize=(8, 6))
sns.histplot(df['power-generated'], bins=50, kde=True, color='skyblue')
plt.title("Distribution of Power Generated")
plt.xlabel("Power Generated")
plt.ylabel("Frequency")
plt.show()

correlations = df.corr()["power-generated"].drop("power-generated").sort_values(ascending=False)
print("\nFeature correlation with 'power-generated':\n", correlations)

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

df_cleaned = df.dropna()

X = df_cleaned.drop("power-generated", axis=1)
y = df_cleaned["power-generated"]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

lr = LinearRegression()
rf = RandomForestRegressor(random_state=42)
gb = GradientBoostingRegressor(random_state=42)

lr.fit(X_train_scaled, y_train)
rf.fit(X_train_scaled, y_train)
gb.fit(X_train_scaled, y_train)

lr_preds = lr.predict(X_test_scaled)
rf_preds = rf.predict(X_test_scaled)
gb_preds = gb.predict(X_test_scaled)

def evaluate_model(y_true, y_pred, model_name="Model"):
    print(f"{model_name} Performance:")
    print(f"R2 Score: {r2_score(y_true, y_pred)}")
    print(f"Mean Absolute Error: {mean_absolute_error(y_true, y_pred)}")
    print(f"Mean Squared Error: {mean_squared_error(y_true, y_pred)}")
    print(f"Root Mean Squared Error: {np.sqrt(mean_squared_error(y_true, y_pred))}")
    print("-" * 40)

evaluate_model(y_test, lr_preds, "Linear Regression")
evaluate_model(y_test, rf_preds, "Random Forest")
evaluate_model(y_test, gb_preds, "Gradient Boosting")

best_model = gb

import joblib

# Save model and scaler
joblib.dump(gb, "gradient_boosting_model.pkl")
joblib.dump(scaler, "scaler.pkl")

pip install streamlit